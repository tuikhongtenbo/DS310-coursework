{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài 1: Thực hiện xây dựng mô hình dự đoán cho bài toán phân tích cảm xúc (sentiment-based) dựa trên bộ dữ liệu UIT-VSFC. Có thể chọn 1 bộ pre-trained embedding khác. (Tham khảo tại đây: https://github.com/vietnlp/etnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:15.760924Z",
     "iopub.status.busy": "2025-11-28T01:16:15.760404Z",
     "iopub.status.idle": "2025-11-28T01:16:20.950804Z",
     "shell.execute_reply": "2025-11-28T01:16:20.949856Z",
     "shell.execute_reply.started": "2025-11-28T01:16:15.760887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvi\n",
      "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyvi) (1.2.2)\n",
      "Collecting sklearn-crfsuite (from pyvi)\n",
      "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (3.6.0)\n",
      "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
      "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->pyvi) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\n",
      "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
      "Successfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:20.952610Z",
     "iopub.status.busy": "2025-11-28T01:16:20.952369Z",
     "iopub.status.idle": "2025-11-28T01:16:25.162431Z",
     "shell.execute_reply": "2025-11-28T01:16:25.161565Z",
     "shell.execute_reply.started": "2025-11-28T01:16:20.952584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import Counter\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_score, recall_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:25.163746Z",
     "iopub.status.busy": "2025-11-28T01:16:25.163336Z",
     "iopub.status.idle": "2025-11-28T01:16:25.238398Z",
     "shell.execute_reply": "2025-11-28T01:16:25.237597Z",
     "shell.execute_reply.started": "2025-11-28T01:16:25.163696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_data_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    return data\n",
    "\n",
    "# train\n",
    "train_data = read_data_json('/kaggle/input/uit-vsfc/UIT-VSFC-train.json')\n",
    "# dev\n",
    "dev_data = read_data_json('/kaggle/input/uit-vsfc/UIT-VSFC-dev.json')\n",
    "# test\n",
    "test_data = read_data_json('/kaggle/input/uit-vsfc/UIT-VSFC-test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:25.240473Z",
     "iopub.status.busy": "2025-11-28T01:16:25.240246Z",
     "iopub.status.idle": "2025-11-28T01:16:31.808479Z",
     "shell.execute_reply": "2025-11-28T01:16:31.807678Z",
     "shell.execute_reply.started": "2025-11-28T01:16:25.240456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build vocab\n",
    "train_sentences = [item['sentence'] for item in train_data]\n",
    "V = []\n",
    "for t in train_sentences:\n",
    "    tokenized_sentence = ViTokenizer.tokenize(t)\n",
    "    V = V + tokenized_sentence.split()\n",
    "    \n",
    "V = list(set(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:31.809476Z",
     "iopub.status.busy": "2025-11-28T01:16:31.809257Z",
     "iopub.status.idle": "2025-11-28T01:16:31.816863Z",
     "shell.execute_reply": "2025-11-28T01:16:31.815899Z",
     "shell.execute_reply.started": "2025-11-28T01:16:31.809459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Word to index\n",
    "word2idx = {word: idx for idx, word in enumerate(V)}\n",
    "word2idx['PAD'] = 0\n",
    "word2idx['UNK'] = 1\n",
    "\n",
    "# Index to word\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "# Label to index\n",
    "unique_labels = sorted(list(set([item['sentiment'] for item in train_data])))\n",
    "label2idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:31.817845Z",
     "iopub.status.busy": "2025-11-28T01:16:31.817579Z",
     "iopub.status.idle": "2025-11-28T01:16:34.938896Z",
     "shell.execute_reply": "2025-11-28T01:16:34.938266Z",
     "shell.execute_reply.started": "2025-11-28T01:16:31.817827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# DATASET + DATALOADER\n",
    "# ============================\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encoded_sentences, labels):\n",
    "        self.encoded_sentences = encoded_sentences\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.encoded_sentences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Encode function\n",
    "def encode_sentence(sentence, max_length):\n",
    "    tokenized = ViTokenizer.tokenize(sentence).split()\n",
    "    indices = [word2idx.get(token, word2idx['UNK']) for token in tokenized]\n",
    "    \n",
    "    if max_length:\n",
    "        if len(indices) > max_length:\n",
    "            indices = indices[:max_length]\n",
    "        else:\n",
    "            indices = indices + [word2idx['PAD']] * (max_length - len(indices))\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# Encode sentences\n",
    "train_encoded = [encode_sentence(item['sentence'], max_length=256) for item in train_data]\n",
    "train_labels = [label2idx[item['sentiment']] for item in train_data]\n",
    "\n",
    "dev_encoded = [encode_sentence(item['sentence'], max_length=256) for item in dev_data]\n",
    "dev_labels = [label2idx[item['sentiment']] for item in dev_data]\n",
    "\n",
    "test_encoded = [encode_sentence(item['sentence'], max_length=256) for item in test_data]\n",
    "test_labels = [label2idx[item['sentiment']] for item in test_data]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = SentimentDataset(train_encoded, train_labels)\n",
    "dev_dataset = SentimentDataset(dev_encoded, dev_labels)\n",
    "test_dataset = SentimentDataset(test_encoded, test_labels)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:34.939823Z",
     "iopub.status.busy": "2025-11-28T01:16:34.939605Z",
     "iopub.status.idle": "2025-11-28T01:16:37.839073Z",
     "shell.execute_reply": "2025-11-28T01:16:37.838400Z",
     "shell.execute_reply.started": "2025-11-28T01:16:34.939805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# LOAD PRETRAINED W2V_NER.VEC\n",
    "# ============================\n",
    "embedding_dim = 300\n",
    "embeddings_index = {}\n",
    "\n",
    "with open(\"/kaggle/input/embedding-model/FastText_ner.vec\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().split(\" \")\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vector\n",
    "\n",
    "\n",
    "# ============================\n",
    "# BUILD EMBEDDING MATRIX\n",
    "# ============================\n",
    "embedding_matrix = np.zeros((len(word2idx), embedding_dim))\n",
    "\n",
    "for word, idx in word2idx.items():\n",
    "    vector = embeddings_index.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[idx] = vector\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:37.840277Z",
     "iopub.status.busy": "2025-11-28T01:16:37.839885Z",
     "iopub.status.idle": "2025-11-28T01:16:38.022349Z",
     "shell.execute_reply": "2025-11-28T01:16:38.021742Z",
     "shell.execute_reply.started": "2025-11-28T01:16:37.840251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (embedding): Embedding(3706, 300)\n",
       "  (output): Linear(in_features=300, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# MODEL WITH PRETRAINED EMBEDDING\n",
    "# ============================\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, embedding_matrix):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix, requires_grad=True)\n",
    "\n",
    "        self.output = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x) # [batch, seq_len, embed_dim]\n",
    "        doc_vec = embeds.mean(dim=1) # Mean-pooling\n",
    "        logits = self.output(doc_vec) \n",
    "        return logits\n",
    "\n",
    "model = Classifier(vocab_size=len(word2idx), embed_dim=embedding_dim, num_classes=len(idx2label), embedding_matrix=embedding_matrix)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:38.023501Z",
     "iopub.status.busy": "2025-11-28T01:16:38.023143Z",
     "iopub.status.idle": "2025-11-28T01:16:40.709861Z",
     "shell.execute_reply": "2025-11-28T01:16:40.709258Z",
     "shell.execute_reply.started": "2025-11-28T01:16:38.023475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# TRAINING SETUP\n",
    "# ============================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.5)\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# ============================\n",
    "# TRAIN LOOP\n",
    "# ============================\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            preds.extend(pred.cpu().tolist())\n",
    "            trues.extend(y.cpu().tolist())\n",
    "    return (\n",
    "        accuracy_score(trues, preds),\n",
    "        f1_score(trues, preds, average=\"macro\"),\n",
    "        precision_score(trues, preds, average=\"macro\"),\n",
    "        recall_score(trues, preds, average=\"macro\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:16:40.711948Z",
     "iopub.status.busy": "2025-11-28T01:16:40.711573Z",
     "iopub.status.idle": "2025-11-28T01:17:11.558780Z",
     "shell.execute_reply": "2025-11-28T01:17:11.557979Z",
     "shell.execute_reply.started": "2025-11-28T01:16:40.711930Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 — Dev Acc: 0.8907, F1: 0.7186\n",
      "*** Best model updated at epoch 1 with F1: 0.7186 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 — Dev Acc: 0.6147, F1: 0.3981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 — Dev Acc: 0.7833, F1: 0.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 — Dev Acc: 0.8181, F1: 0.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 — Dev Acc: 0.8402, F1: 0.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 — Dev Acc: 0.8686, F1: 0.6988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 — Dev Acc: 0.8876, F1: 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 — Dev Acc: 0.8579, F1: 0.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 — Dev Acc: 0.8427, F1: 0.7223\n",
      "*** Best model updated at epoch 9 with F1: 0.7223 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 — Dev Acc: 0.8459, F1: 0.7260\n",
      "*** Best model updated at epoch 10 with F1: 0.7260 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 — Dev Acc: 0.6627, F1: 0.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 — Dev Acc: 0.8945, F1: 0.7356\n",
      "*** Best model updated at epoch 12 with F1: 0.7356 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 — Dev Acc: 0.8882, F1: 0.6146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 — Dev Acc: 0.8661, F1: 0.7456\n",
      "*** Best model updated at epoch 14 with F1: 0.7456 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 — Dev Acc: 0.8478, F1: 0.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 — Dev Acc: 0.8939, F1: 0.7682\n",
      "*** Best model updated at epoch 16 with F1: 0.7682 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 — Dev Acc: 0.8787, F1: 0.7226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 — Dev Acc: 0.8692, F1: 0.7241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 — Dev Acc: 0.8238, F1: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 — Dev Acc: 0.8604, F1: 0.7454\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for X, y in train_bar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Evaluate on dev set\n",
    "    acc, f1, prec, rec = evaluate(dev_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} — Dev Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_state = model.state_dict()\n",
    "        torch.save(best_model_state, \"best_model.pth\")\n",
    "        print(f\"*** Best model updated at epoch {epoch+1} with F1: {best_f1:.4f} ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T01:17:11.560000Z",
     "iopub.status.busy": "2025-11-28T01:17:11.559680Z",
     "iopub.status.idle": "2025-11-28T01:17:11.723094Z",
     "shell.execute_reply": "2025-11-28T01:17:11.722438Z",
     "shell.execute_reply.started": "2025-11-28T01:17:11.559982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST RESULT ===\n",
      "Accuracy : 0.8762\n",
      "F1       : 0.7364\n",
      "Precision: 0.7472\n",
      "Recall   : 0.7298\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "#  TEST\n",
    "# ============================\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate on test set\n",
    "acc, f1, prec, rec = evaluate(test_loader)\n",
    "print(\"\\n=== TEST RESULT ===\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"F1       : {f1:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8856847,
     "sourceId": 13901578,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8857064,
     "sourceId": 13901942,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
